{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b51f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "from skimage import transform, img_as_ubyte\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed,ProcessPoolExecutor\n",
    "from skimage import transform\n",
    "from skimage.util import img_as_ubyte\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from faker import Faker\n",
    "\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "from cr_renderer import CrelloV5Renderer\n",
    "fonts_path = huggingface_hub.hf_hub_download(\n",
    "    repo_id=\"cyberagent/crello\",\n",
    "    filename=\"resources/fonts.pickle\",\n",
    "    repo_type=\"dataset\",\n",
    "    revision=\"5.0.0\",\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "model_path = \"nanonets/Nanonets-OCR2-3B\"\n",
    "\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path, \n",
    "    torch_dtype=\"auto\", \n",
    "    device_map=\"auto\", \n",
    "    # attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f397d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mirror_distortion(text):\n",
    "    \n",
    "    with open(\"mirror_distortion.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        mirror_data = json.load(f)\n",
    "        \n",
    "    number=random.randint(0,len(text)//2)\n",
    "    random_index=random.sample(range(len(text)),k=number)\n",
    "    text_copy=list(text)\n",
    "    \n",
    "    for idx in random_index:\n",
    "        working_char=text[idx]\n",
    "        mirror_type=['HORIZONTAL_MIRROR_MULTI','VERTICAL_MIRROR_MULTI','ROTATION_180_MULTI']\n",
    "\n",
    "        attempt=0\n",
    "        while(attempt<10):\n",
    "            selected_type=random.choice(mirror_type)\n",
    "            if(working_char not in mirror_data[selected_type]):\n",
    "                attempt+=1\n",
    "                continue\n",
    "\n",
    "            replacement=random.choice(mirror_data[selected_type][working_char])\n",
    "            print(\"Replacing \",working_char,\" with \",replacement)\n",
    "            text_copy[idx]=replacement\n",
    "            attempt+=1\n",
    "            break\n",
    "\n",
    "    text_copy=''.join(text_copy)\n",
    "    return text_copy\n",
    "\n",
    "def char_level_repetition_distortion(text: str, max_repeats: int = 2):\n",
    "\n",
    "    num_positions = random.randint(1, min(4, len(text)))  # up to 4 random spots\n",
    "    random_indices = random.sample(range(len(text)), k=num_positions)\n",
    "\n",
    "    distorted = \"\"\n",
    "    for i, ch in enumerate(text):\n",
    "        distorted += ch\n",
    "        if i in random_indices:\n",
    "            repeat_count = random.randint(1, max_repeats)\n",
    "            distorted += ch * repeat_count\n",
    "\n",
    "    return distorted\n",
    "\n",
    "def char_level_drop_distortion(text: str, max_drops: int = 3):\n",
    "    \n",
    "    num_drops = random.randint(1, min(max_drops, len(text) // 2))\n",
    "    drop_indices = set(random.sample(range(len(text)), k=num_drops))\n",
    "\n",
    "    distorted = \"\".join(ch for i, ch in enumerate(text) if i not in drop_indices)\n",
    "    return distorted\n",
    "\n",
    "def adjacent_char_swap_distortion(text: str, max_swaps: int = 2):\n",
    "    \"\"\"Swaps two adjacent alphanumeric characters at random positions.\"\"\"\n",
    "    text_list = list(text)\n",
    "    if len(text_list) < 2:\n",
    "        return text\n",
    "\n",
    "    # Find valid indices to swap (don't want to swap a letter with a space or punctuation)\n",
    "    valid_indices = [\n",
    "        i for i in range(len(text_list) - 1)\n",
    "        if text_list[i].isalnum() and text_list[i+1].isalnum()\n",
    "    ]\n",
    "    \n",
    "    if not valid_indices:\n",
    "        return text\n",
    "\n",
    "    num_swaps = random.randint(1, min(max_swaps, len(valid_indices)))\n",
    "    swap_indices = random.sample(valid_indices, k=num_swaps)\n",
    "    \n",
    "    for idx in swap_indices:\n",
    "        # Check again in case a previous swap invalidated this one (unlikely but safe)\n",
    "        if text_list[idx].isalnum() and text_list[idx+1].isalnum():\n",
    "            text_list[idx], text_list[idx+1] = text_list[idx+1], text_list[idx]\n",
    "            \n",
    "    return \"\".join(text_list)\n",
    "\n",
    "def same_char_distortion(text):\n",
    "    # print(\"Input: \",text)\n",
    "    with open(\"same_char.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        same_char_data = json.load(f)\n",
    "    \n",
    "    number=random.randint(0,len(text)//2)\n",
    "    random_index=random.sample(range(len(text)),k=number)\n",
    "    \n",
    "    text_copy=list(text)                            \n",
    "    for idx in random_index:\n",
    "    \n",
    "        working_char=text[idx]\n",
    "        \n",
    "        if(working_char in same_char_data):\n",
    "            replacement=random.choice(same_char_data[working_char])\n",
    "            print(\"Replacing \",working_char,\" with \",replacement)\n",
    "            text_copy[idx]=replacement\n",
    "            break\n",
    "    \n",
    "    text_copy=''.join(text_copy)\n",
    "    # print(\"Output: \",text_copy)\n",
    "    return text_copy\n",
    "\n",
    "def case_shuffle_distortion(text):\n",
    "    \"\"\"Randomly shuffles case of all characters\"\"\"\n",
    "    distorted = \"\"\n",
    "    for ch in text:\n",
    "        if ch.isalpha():\n",
    "            distorted += ch.upper() if random.random() < 0.5 else ch.lower()\n",
    "        else:\n",
    "            distorted += ch\n",
    "    return distorted\n",
    "\n",
    "def noise_injection_distortion(text, max_noise: int = 5):\n",
    "    \"\"\"Injects random noise characters at random positions\"\"\"\n",
    "    noise_chars = ['·', '˙', '`', '´', '¨', '˚', '°']\n",
    "    \n",
    "    text_list = list(text)\n",
    "    num_noise = random.randint(1, min(max_noise, len(text)))\n",
    "    \n",
    "    for _ in range(num_noise):\n",
    "        idx = random.randint(0, len(text_list))\n",
    "        text_list.insert(idx, random.choice(noise_chars))\n",
    "    \n",
    "    return ''.join(text_list)\n",
    "\n",
    "def ocr_confusion_distortion(text: str, max_confusions: int = 2):\n",
    "    ocr_pairs = {\n",
    "        # Multi-character to single character confusions\n",
    "        'rn': 'm', 'nn': 'u', 'vv': 'w', 'uu': 'w', 'ii': 'u',\n",
    "        'cl': 'd', 'li': 'h', 'Il': 'H', 'ln': 'h', 'rr': 'n',\n",
    "        'iii': 'm', 'ri': 'n', 'RN': 'M', 'VV': 'W', 'UU': 'W',\n",
    "        'tt': 'H', 'IVI': 'M', 'AI': 'N', 'NN': 'M', 'AA': 'M',\n",
    "        \n",
    "        # Single character to multi-character confusions\n",
    "        'm': 'rn', 'w': 'vv', 'u': 'ii', 'n': 'ri', 'h': 'li',\n",
    "        'M': 'RN', 'W': 'VV', 'H': 'tt', 'N': 'AI',\n",
    "        \n",
    "        # Number/letter confusions (multi-char patterns)\n",
    "        '0O': 'OO', 'O0': '00', 'l1': '11', '1l': 'll', \n",
    "        'I1': '11', '1I': 'II', 'S5': '55', '5S': 'SS',\n",
    "        'B8': '88', '8B': 'BB', 'G6': '66', '6G': 'GG',\n",
    "        \n",
    "        # Common word-specific OCR errors\n",
    "        'tlie': 'the', 'tbe': 'the', 'tiie': 'the', 'thc': 'the',\n",
    "        'aud': 'and', 'arid': 'and', 'aiid': 'and', 'ancl': 'and',\n",
    "        'of': 'ol', 'ot': 'of', 'ol': 'of', 'for': 'lor', 'tor': 'for',\n",
    "        'Mr': 'Nfr', 'Mrs': 'Nfrs', 'Mr.': 'Mr,', 'Mrs.': 'Mrs,',\n",
    "        'was': 'vvas', 'will': 'vvill', 'with': 'witli', 'from': 'frorn',\n",
    "        'that': 'tliat', 'this': 'tliis', 'which': 'wliich', 'when': 'wlien',\n",
    "        'been': 'beeu', 'have': 'liave', 'said': 'sald', 'upon': 'upou',\n",
    "        \n",
    "        # Long s (historical OCR)\n",
    "        'fs': 'ss', 'fl': 'fi', 'fi': 'fl', 'fh': 'sh', 'ft': 'st',\n",
    "        \n",
    "        # Punctuation and special character confusions\n",
    "        ').': ')', '.)': '.)', ',)': ').', ',.': ',', '.,': '.,',\n",
    "        ';\"': ';', '\":': ':', \"';\": \"'\", \".'\": \".'\",\n",
    "        \n",
    "        # Common prefix/suffix errors\n",
    "        'tlie': 'the', 'witli': 'with', 'wliich': 'which', 'tliey': 'they',\n",
    "        'tliis': 'this', 'liere': 'here', 'wlien': 'when', 'wliat': 'what',\n",
    "        'tbing': 'thing', 'tbat': 'that', 'tion': 'lion', 'sion': 'siou',\n",
    "        \n",
    "        # Double letter confusions\n",
    "        'ff': 'fi', 'fi': 'ff', 'tt': 'H', 'il': 'II', 'oo': 'œ',\n",
    "        \n",
    "        # Capitalization OCR errors\n",
    "        'Tlie': 'The', 'Tbe': 'The', 'Wlien': 'When', 'Witli': 'With',\n",
    "        'Wliich': 'Which', 'Frorn': 'From', 'Tliis': 'This', 'Tliat': 'That'\n",
    "    }\n",
    "    \n",
    "    # Attempt replacements\n",
    "    for _ in range(max_confusions):\n",
    "        for pattern, replacement in ocr_pairs.items():\n",
    "            if pattern in text and random.random() < 0.3:\n",
    "                positions = [i for i in range(len(text) - len(pattern) + 1) \n",
    "                           if text[i:i+len(pattern)] == pattern]\n",
    "                if positions:\n",
    "                    idx = random.choice(positions)\n",
    "                    text = text[:idx] + replacement + text[idx+len(pattern):]\n",
    "                    break\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def subscript_superscript_distortion(text: str, max_conversions: int = 2):\n",
    "    superscripts = {'0': '⁰', '1': '¹', '2': '²', '3': '³', '4': '⁴',\n",
    "                   '5': '⁵', '6': '⁶', '7': '⁷', '8': '⁸', '9': '⁹',\n",
    "                   'a': 'ᵃ', 'b': 'ᵇ', 'c': 'ᶜ', 'd': 'ᵈ', 'e': 'ᵉ'}\n",
    "    \n",
    "    subscripts = {'0': '₀', '1': '₁', '2': '₂', '3': '₃', '4': '₄',\n",
    "                 '5': '₅', '6': '₆', '7': '₇', '8': '₈', '9': '₉'}\n",
    "    \n",
    "    conversion_map = {**superscripts, **subscripts}\n",
    "    \n",
    "    text_list = list(text)\n",
    "    valid_indices = [i for i, ch in enumerate(text) if ch in conversion_map]\n",
    "    \n",
    "    if not valid_indices:\n",
    "        return text\n",
    "    \n",
    "    num_conversions = random.randint(1, min(max_conversions, len(valid_indices)))\n",
    "    conversion_indices = random.sample(valid_indices, k=num_conversions)\n",
    "    \n",
    "    for idx in conversion_indices:\n",
    "        text_list[idx] = conversion_map[text[idx]]\n",
    "    \n",
    "    return ''.join(text_list)\n",
    "\n",
    "\n",
    "def zalgo_distortion(text: str, max_intensity: int = 3, max_chars: int = 5):\n",
    "    \n",
    "    if(len(text)<=8):\n",
    "        return text\n",
    "    \"\"\"Adds stacking 'combining' diacritic marks to random characters.\"\"\"\n",
    "    # A selection of combining marks\n",
    "    DIACRITICS = [\n",
    "        # Above\n",
    "        '\\u0300', '\\u0301', '\\u0302', '\\u0303', '\\u0304', '\\u0305', '\\u0306', '\\u0307', \n",
    "        '\\u0308', '\\u030A', '\\u030B', '\\u030C', '\\u030D', '\\u030E', '\\u030F', '\\u0310', \n",
    "        '\\u0311',\n",
    "        # Middle (includes your strikethrough)\n",
    "        '\\u0334', '\\u0335', '\\u0336', '\\u0337', '\\u0338',\n",
    "        # Below\n",
    "        '\\u0316', '\\u0317', '\\u0318', '\\u0319', '\\u031A', '\\u031B', '\\u031C', '\\u031D',\n",
    "        '\\u031E', '\\u031F', '\\u0320', '\\u0321', '\\u0322', '\\u0323', '\\u0324', '\\u0325',\n",
    "        '\\u0326', '\\u0327', '\\u0328', '\\u0329', '\\u032A'\n",
    "    ]\n",
    "    \n",
    "    text_list = list(text)\n",
    "    \n",
    "    # Find non-space characters to distort\n",
    "    valid_indices = [i for i, char in enumerate(text) if not char.isspace()]\n",
    "    if not valid_indices:\n",
    "        return text\n",
    "\n",
    "    num_chars_to_distort = random.randint(1, min(max_chars, len(valid_indices)))\n",
    "    distort_indices = random.sample(valid_indices, k=num_chars_to_distort)\n",
    "    \n",
    "    for idx in sorted(distort_indices, reverse=True):\n",
    "        num_diacritics = random.randint(1, max_intensity)\n",
    "        for _ in range(num_diacritics):\n",
    "            text_list.insert(idx + 1, random.choice(DIACRITICS))\n",
    "    \n",
    "    return \"\".join(text_list)\n",
    "\n",
    "def render_faker_text_on_image(image_path, num_texts=5, font_path=None):\n",
    "    # img = Image.open(image_path)\n",
    "    # Initialize Faker\n",
    "    fake = Faker()\n",
    "    img=image_path.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "\n",
    "    if font_path:\n",
    "        font = ImageFont.truetype(font_path, 12)\n",
    "    else:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for _ in range(num_texts):\n",
    "        text = fake.sentence()  # generate meaningful sentence dynamically\n",
    "        \n",
    "        x = random.randint(0, max(0, width - 100))\n",
    "        y = random.randint(0, max(0, height - 20))\n",
    "        color = tuple(random.randint(0,100) for _ in range(3))\n",
    "        draw.text((x, y), text, fill=color, font=font)\n",
    "\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def distort_text(example,distortion_list):\n",
    "    text=example['text']\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ind in range(len(text)):\n",
    "        working_text=text[ind]\n",
    "        if(working_text==''):\n",
    "            continue\n",
    "        else:\n",
    "            for distortion in distortion_list:\n",
    "                if(distortion=='repetition'):\n",
    "                    working_text=char_level_repetition_distortion(working_text)\n",
    "                elif(distortion=='drop'):\n",
    "                    working_text=char_level_drop_distortion(working_text)\n",
    "                elif(distortion=='mirror'):\n",
    "                    working_text=mirror_distortion(working_text)\n",
    "                elif(distortion=='same_char'):\n",
    "                    working_text=same_char_distortion(working_text)\n",
    "                elif(distortion=='case_shuffle'):\n",
    "                    working_text=case_shuffle_distortion(working_text)\n",
    "                elif(distortion=='noise_injection'):\n",
    "                    working_text=noise_injection_distortion(working_text)\n",
    "                elif(distortion=='adjacent_char_swap'):\n",
    "                    working_text=adjacent_char_swap_distortion(working_text)\n",
    "                elif(distortion=='zalgo'):\n",
    "                    working_text=zalgo_distortion(working_text)\n",
    "                elif(distortion=='ocr_confusion'):\n",
    "                    working_text=ocr_confusion_distortion(working_text)\n",
    "                elif(distortion=='subscript_superscript'):\n",
    "                    working_text=subscript_superscript_distortion(working_text)\n",
    "                    \n",
    "        \n",
    "        text[ind]=working_text\n",
    "    example['text']=text\n",
    "    return example\n",
    "\n",
    "def distort_image(img,distortion_type):\n",
    "    if(distortion_type=='faker_text'):\n",
    "        distorted_img=render_faker_text_on_image(img, \"temp_output.jpg\", num_texts=5)\n",
    "    return distorted_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score(image, input_text, max_new_tokens=100):\n",
    "    \n",
    "    prompt = \"\"\"Extract the text from the provided image. Remember dont print any extra text just return the text rendered on the image. Also try to ignore the lines or borders used for just styling\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "        ]},\n",
    "    ]\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = processor(text=[text], images=[image], padding=True, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(model.device)\n",
    "    \n",
    "    output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "    \n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    \n",
    "    import Levenshtein\n",
    "    val=Levenshtein.distance(output_text[0],input_text)\n",
    "    return val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ed5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # # Pulkit- Just change the start and end values\n",
    "    start=0\n",
    "    end=10\n",
    "    type_of_process=1 \n",
    "    min_val=3\n",
    "    max_val=11\n",
    "    total_sample=150\n",
    "    batch_size=16\n",
    "\n",
    "    output_dir = \"dataset\"\n",
    "    final_csv_path=os.path.join(output_dir,f\"final_dataset_{start}_{end}\")\n",
    "    final_json_path=os.path.join(output_dir,f\"scores_data_{start}_{end}\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        os.mkdir(os.path.join(output_dir, \"win\"))\n",
    "        for n in range(1, batch_size+1):  \n",
    "            os.mkdir(os.path.join(output_dir, f\"lose{n}\"))\n",
    "\n",
    "\n",
    "    # Load the dataset from Hugging Face\n",
    "    dataset = load_dataset(\"data-is-better-together/open-image-preferences-v1-binarized\")\n",
    "    renderer = CrelloV5Renderer(dataset.features, fonts_path)\n",
    "\n",
    "    available_distortions_text_only = [\n",
    "        char_level_drop_distortion,\n",
    "        char_level_repetition_distortion,\n",
    "        adjacent_char_swap_distortion,\n",
    "        case_shuffle_distortion,\n",
    "        noise_injection_distortion,\n",
    "        ocr_confusion_distortion,\n",
    "        subscript_superscript_distortion,\n",
    "        zalgo_distortion,\n",
    "        mirror_distortion,\n",
    "        same_char_distortion,\n",
    "    ]\n",
    "    \n",
    "    available_distortions_image_only = [\n",
    "        render_faker_text_on_image,\n",
    "    ]\n",
    "    \n",
    "    available_distortion=available_distortions_text_only + available_distortions_image_only\n",
    "\n",
    "    lose_cols = [f\"lose_image{i}\" for i in range(1, batch_size+1)]\n",
    "    final_dataset = pd.DataFrame(columns=[\"prompt\", \"win_image\"] + lose_cols)\n",
    "\n",
    "    json_dict_for_scores=[]\n",
    "    \n",
    "    for i in range(start,end):\n",
    "\n",
    "        temp_dict={}\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing row {i}\")\n",
    "            \n",
    "        example = dataset['train'][i]\n",
    "\n",
    "        try:\n",
    "            \n",
    "            \n",
    "            win_image = renderer.render(example)\n",
    "            if win_image is None:\n",
    "                continue\n",
    "\n",
    "            distorted_images = []\n",
    "\n",
    "            # Generate 100 distorted images\n",
    "            import time\n",
    "            start=time.time()\n",
    "            \n",
    "\n",
    "            def generate_distorted(ind):\n",
    "               \n",
    "                num_ops = random.randint(3, len(available_distortion))\n",
    "\n",
    "                funcs = random.choices(available_distortion, k=num_ops)\n",
    "                flag=0\n",
    "                \n",
    "                for i in funcs:\n",
    "                    if i in available_distortions_image_only:\n",
    "                        flag=1\n",
    "                        \n",
    "                distorted = distort_text(funcs, example)\n",
    "                \n",
    "                if flag==1:\n",
    "                    distorted_img=renderer.render(distorted)\n",
    "                    distorted=distort_image(distorted_img,'faker_text')\n",
    "                    \n",
    "                if distorted is None:\n",
    "                    return None\n",
    "                return distorted\n",
    "\n",
    "            with ProcessPoolExecutor(max_workers=50) as executor:\n",
    "                futures = [executor.submit(generate_distorted,ind) for ind in range(total_sample)]\n",
    "\n",
    "                for future in as_completed(futures):\n",
    "                    distorted = future.result()\n",
    "                    if distorted is None:\n",
    "                        continue\n",
    "                    time_start = time.time()\n",
    "                    score = score(distorted, example['text'])   #---Need to chnage this thing\n",
    "                    distorted_images.append((distorted, score))\n",
    "                    # print(score)\n",
    "            \n",
    "            if i % 200 == 0:  # Note: Use ==, not just `if i % 200`\n",
    "                save_folder_path=os.path.join(output_dir, f\"ckpt_{i}\")\n",
    "                os.makedirs(save_folder_path, exist_ok=True)\n",
    "                for idx, (img, _) in enumerate(distorted_images):\n",
    "                    save_path=os.path.join(save_folder_path,f'{idx}.png')\n",
    "                    cv2.imwrite(save_path, img)\n",
    "\n",
    "\n",
    "            print(f\"Distortion time: {time.time() - start:.2f} seconds\")\n",
    "            def max_variation_dp(data, k):\n",
    "                from functools import lru_cache\n",
    "\n",
    "                data = sorted(data, key=lambda x: x[1])\n",
    "                values = [val for val in data]\n",
    "                scores = [val[1] for val in data]\n",
    "                N = len(data)\n",
    "\n",
    "                # Use indices instead of actual score values to make caching effective\n",
    "                @lru_cache(maxsize=None)\n",
    "                def dp(pos, rem, last_idx):\n",
    "                    if rem == 0:\n",
    "                        return 0, []\n",
    "                    if pos == N:\n",
    "                        return float(\"-inf\"), []\n",
    "\n",
    "                    # Option 1: Take current element\n",
    "                    take_score = abs(scores[pos] - scores[last_idx]) if last_idx != -1 else 0\n",
    "                    take_sum, take_list = dp(pos + 1, rem - 1, pos)\n",
    "                    take_sum += take_score\n",
    "\n",
    "                    # Option 2: Skip current element\n",
    "                    skip_sum, skip_list = dp(pos + 1, rem, last_idx)\n",
    "\n",
    "                    if take_sum > skip_sum:\n",
    "                        return take_sum, [values[pos]] + take_list\n",
    "                    else:\n",
    "                        return skip_sum, skip_list\n",
    "\n",
    "                _, best_subset = dp(0, k, -1)\n",
    "                return best_subset\n",
    "\n",
    "\n",
    "            distorted_images = sorted(distorted_images, key=lambda x: x[1])\n",
    "            distorted_images1= distorted_images[:len(distorted_images)//3]\n",
    "            distorted_images2= distorted_images[len(distorted_images)//3:len(distorted_images)//2]\n",
    "            distorted_images3= distorted_images[len(distorted_images)//2:]\n",
    "            sample_from_each_bucket=batch_size//3\n",
    "            best_subset = max_variation_dp(distorted_images1, k=sample_from_each_bucket)\n",
    "            best_subset += max_variation_dp(distorted_images2, k=sample_from_each_bucket)\n",
    "            best_subset+=max_variation_dp(distorted_images3, k=batch_size-2*sample_from_each_bucket)\n",
    "\n",
    "            best_subset=sorted(best_subset, key=lambda x: x[1])\n",
    "            if len(best_subset) < batch_size:\n",
    "                continue\n",
    "\n",
    "            # Save win image\n",
    "            win_path = os.path.join(output_dir, \"win\", f\"{i}.png\")\n",
    "            if win_image.dtype != np.uint8:\n",
    "                win_image = np.clip(win_image, 0, 255).astype(np.uint8)\n",
    "            cv2.imwrite(win_path, win_image)\n",
    "\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            lose_paths = []\n",
    "            for j, (img, score_val) in enumerate(best_subset):\n",
    "                path = os.path.join(output_dir, f\"lose{j+1}\", f\"{i}.png\")\n",
    "                cv2.imwrite(path, img)\n",
    "                lose_paths.append(path)\n",
    "                temp_dict[j+1]=score_val\n",
    "\n",
    "            win_image_score= score(win_image, example['text'])\n",
    "            temp_dict['win_image_score']=win_image_score\n",
    "\n",
    "            #Pulkit- Comment this line to avoid visualization\n",
    "            # visualize_generated_dataset(best_subset, win_image, prompt,win_image_score)\n",
    "\n",
    "            # Append to final dataset\n",
    "            data_row = {\"prompt\": example['prompt'], \"win_image\": win_path}\n",
    "            for k in range(batch_size):\n",
    "                data_row[f\"lose_image{k+1}\"] = lose_paths[k]\n",
    "\n",
    "            final_dataset = pd.concat([final_dataset, pd.DataFrame([data_row])], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on row {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "        json_dict_for_scores.append({i: temp_dict})\n",
    "        # if i%100==0:\n",
    "        with open(final_json_path,'w') as f:\n",
    "            json.dump(json_dict_for_scores, f, indent=4)\n",
    "    # Save full dataset\n",
    "    final_dataset.to_csv(final_csv_path, index=False)\n",
    "\n",
    "   \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
