{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d09b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"C:\\Users\\pulki\\Downloads\\temp_fold\\cr-renderer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebf4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b51f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from io import BytesIO\n",
    "import json\n",
    "from concurrent.futures import as_completed,ProcessPoolExecutor\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from faker import Faker\n",
    "\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "from cr_renderer import CrelloV5Renderer\n",
    "fonts_path = huggingface_hub.hf_hub_download(\n",
    "    repo_id=\"cyberagent/crello\",\n",
    "    filename=\"resources/fonts.pickle\",\n",
    "    repo_type=\"dataset\",\n",
    "    revision=\"5.0.0\",\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "# model_path = \"nanonets/Nanonets-OCR2-3B\"\n",
    "\n",
    "# model = AutoModelForImageTextToText.from_pretrained(\n",
    "#     model_path, \n",
    "#     torch_dtype=\"auto\", \n",
    "#     device_map=\"auto\", \n",
    "#     # attn_implementation=\"flash_attention_2\"\n",
    "# )\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f397d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "def mirror_distortion(text):\n",
    "    \n",
    "    with open(\"mirror_distortion.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        mirror_data = json.load(f)\n",
    "        \n",
    "    number=random.randint(0,len(text)//2)\n",
    "    random_index=random.sample(range(len(text)),k=number)\n",
    "    text_copy=list(text)\n",
    "    \n",
    "    for idx in random_index:\n",
    "        working_char=text[idx]\n",
    "        mirror_type=['HORIZONTAL_MIRROR_MULTI','VERTICAL_MIRROR_MULTI','ROTATION_180_MULTI']\n",
    "\n",
    "        attempt=0\n",
    "        while(attempt<10):\n",
    "            selected_type=random.choice(mirror_type)\n",
    "            if(working_char not in mirror_data[selected_type]):\n",
    "                attempt+=1\n",
    "                continue\n",
    "\n",
    "            replacement=random.choice(mirror_data[selected_type][working_char])\n",
    "            # print(\"Replacing \",working_char,\" with \",replacement)\n",
    "            text_copy[idx]=replacement\n",
    "            attempt+=1\n",
    "            break\n",
    "\n",
    "    text_copy=''.join(text_copy)\n",
    "    return text_copy\n",
    "\n",
    "def char_level_repetition_distortion(text: str, max_repeats: int = 2):\n",
    "\n",
    "    num_positions = random.randint(1, min(4, len(text)))  # up to 4 random spots\n",
    "    random_indices = random.sample(range(len(text)), k=num_positions)\n",
    "\n",
    "    distorted = \"\"\n",
    "    for i, ch in enumerate(text):\n",
    "        distorted += ch\n",
    "        if i in random_indices:\n",
    "            repeat_count = random.randint(1, max_repeats)\n",
    "            distorted += ch * repeat_count\n",
    "\n",
    "    return distorted\n",
    "\n",
    "def char_level_drop_distortion(text: str, max_drops: int = 3):\n",
    "    \n",
    "    num_drops = random.randint(1, min(max_drops, len(text) // 2))\n",
    "    drop_indices = set(random.sample(range(len(text)), k=num_drops))\n",
    "\n",
    "    distorted = \"\".join(ch for i, ch in enumerate(text) if i not in drop_indices)\n",
    "    return distorted\n",
    "\n",
    "def adjacent_char_swap_distortion(text: str, max_swaps: int = 2):\n",
    "    \"\"\"Swaps two adjacent alphanumeric characters at random positions.\"\"\"\n",
    "    text_list = list(text)\n",
    "    if len(text_list) < 2:\n",
    "        return text\n",
    "\n",
    "    # Find valid indices to swap (don't want to swap a letter with a space or punctuation)\n",
    "    valid_indices = [\n",
    "        i for i in range(len(text_list) - 1)\n",
    "        if text_list[i].isalnum() and text_list[i+1].isalnum()\n",
    "    ]\n",
    "    \n",
    "    if not valid_indices:\n",
    "        return text\n",
    "\n",
    "    num_swaps = random.randint(1, min(max_swaps, len(valid_indices)))\n",
    "    swap_indices = random.sample(valid_indices, k=num_swaps)\n",
    "    \n",
    "    for idx in swap_indices:\n",
    "        # Check again in case a previous swap invalidated this one (unlikely but safe)\n",
    "        if text_list[idx].isalnum() and text_list[idx+1].isalnum():\n",
    "            text_list[idx], text_list[idx+1] = text_list[idx+1], text_list[idx]\n",
    "            \n",
    "    return \"\".join(text_list)\n",
    "\n",
    "def same_char_distortion(text):\n",
    "    # print(\"Input: \",text)\n",
    "    with open(\"same_char.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        same_char_data = json.load(f)\n",
    "    \n",
    "    number=random.randint(0,len(text)//2)\n",
    "    random_index=random.sample(range(len(text)),k=number)\n",
    "    \n",
    "    text_copy=list(text)                            \n",
    "    for idx in random_index:\n",
    "    \n",
    "        working_char=text[idx]\n",
    "        \n",
    "        if(working_char in same_char_data):\n",
    "            replacement=random.choice(same_char_data[working_char])\n",
    "            # print(\"Replacing \",working_char,\" with \",replacement)\n",
    "            text_copy[idx]=replacement\n",
    "            break\n",
    "    \n",
    "    text_copy=''.join(text_copy)\n",
    "    # print(\"Output: \",text_copy)\n",
    "    return text_copy\n",
    "\n",
    "def case_shuffle_distortion(text):\n",
    "    \"\"\"Randomly shuffles case of all characters\"\"\"\n",
    "    distorted = \"\"\n",
    "    for ch in text:\n",
    "        if ch.isalpha():\n",
    "            distorted += ch.upper() if random.random() < 0.5 else ch.lower()\n",
    "        else:\n",
    "            distorted += ch\n",
    "    return distorted\n",
    "\n",
    "def noise_injection_distortion(text, max_noise: int = 5):\n",
    "    \"\"\"Injects random noise characters at random positions\"\"\"\n",
    "    noise_chars = ['·', '˙', '`', '´', '¨', '˚', '°']\n",
    "    \n",
    "    text_list = list(text)\n",
    "    num_noise = random.randint(1, min(max_noise, len(text)))\n",
    "    \n",
    "    for _ in range(num_noise):\n",
    "        idx = random.randint(0, len(text_list))\n",
    "        text_list.insert(idx, random.choice(noise_chars))\n",
    "    \n",
    "    return ''.join(text_list)\n",
    "\n",
    "def ocr_confusion_distortion(text: str, max_confusions: int = 2):\n",
    "    ocr_pairs = {\n",
    "        # Multi-character to single character confusions\n",
    "        'rn': 'm', 'nn': 'u', 'vv': 'w', 'uu': 'w', 'ii': 'u',\n",
    "        'cl': 'd', 'li': 'h', 'Il': 'H', 'ln': 'h', 'rr': 'n',\n",
    "        'iii': 'm', 'ri': 'n', 'RN': 'M', 'VV': 'W', 'UU': 'W',\n",
    "        'tt': 'H', 'IVI': 'M', 'AI': 'N', 'NN': 'M', 'AA': 'M',\n",
    "        \n",
    "        # Single character to multi-character confusions\n",
    "        'm': 'rn', 'w': 'vv', 'u': 'ii', 'n': 'ri', 'h': 'li',\n",
    "        'M': 'RN', 'W': 'VV', 'H': 'tt', 'N': 'AI',\n",
    "        \n",
    "        # Number/letter confusions (multi-char patterns)\n",
    "        '0O': 'OO', 'O0': '00', 'l1': '11', '1l': 'll', \n",
    "        'I1': '11', '1I': 'II', 'S5': '55', '5S': 'SS',\n",
    "        'B8': '88', '8B': 'BB', 'G6': '66', '6G': 'GG',\n",
    "        \n",
    "        # Common word-specific OCR errors\n",
    "        'tlie': 'the', 'tbe': 'the', 'tiie': 'the', 'thc': 'the',\n",
    "        'aud': 'and', 'arid': 'and', 'aiid': 'and', 'ancl': 'and',\n",
    "        'of': 'ol', 'ot': 'of', 'ol': 'of', 'for': 'lor', 'tor': 'for',\n",
    "        'Mr': 'Nfr', 'Mrs': 'Nfrs', 'Mr.': 'Mr,', 'Mrs.': 'Mrs,',\n",
    "        'was': 'vvas', 'will': 'vvill', 'with': 'witli', 'from': 'frorn',\n",
    "        'that': 'tliat', 'this': 'tliis', 'which': 'wliich', 'when': 'wlien',\n",
    "        'been': 'beeu', 'have': 'liave', 'said': 'sald', 'upon': 'upou',\n",
    "        \n",
    "        # Long s (historical OCR)\n",
    "        'fs': 'ss', 'fl': 'fi', 'fi': 'fl', 'fh': 'sh', 'ft': 'st',\n",
    "        \n",
    "        # Punctuation and special character confusions\n",
    "        ').': ')', '.)': '.)', ',)': ').', ',.': ',', '.,': '.,',\n",
    "        ';\"': ';', '\":': ':', \"';\": \"'\", \".'\": \".'\",\n",
    "        \n",
    "        # Common prefix/suffix errors\n",
    "        'tlie': 'the', 'witli': 'with', 'wliich': 'which', 'tliey': 'they',\n",
    "        'tliis': 'this', 'liere': 'here', 'wlien': 'when', 'wliat': 'what',\n",
    "        'tbing': 'thing', 'tbat': 'that', 'tion': 'lion', 'sion': 'siou',\n",
    "        \n",
    "        # Double letter confusions\n",
    "        'ff': 'fi', 'fi': 'ff', 'tt': 'H', 'il': 'II', 'oo': 'œ',\n",
    "        \n",
    "        # Capitalization OCR errors\n",
    "        'Tlie': 'The', 'Tbe': 'The', 'Wlien': 'When', 'Witli': 'With',\n",
    "        'Wliich': 'Which', 'Frorn': 'From', 'Tliis': 'This', 'Tliat': 'That'\n",
    "    }\n",
    "    \n",
    "    # Attempt replacements\n",
    "    for _ in range(max_confusions):\n",
    "        for pattern, replacement in ocr_pairs.items():\n",
    "            if pattern in text and random.random() < 0.3:\n",
    "                positions = [i for i in range(len(text) - len(pattern) + 1) \n",
    "                           if text[i:i+len(pattern)] == pattern]\n",
    "                if positions:\n",
    "                    idx = random.choice(positions)\n",
    "                    text = text[:idx] + replacement + text[idx+len(pattern):]\n",
    "                    break\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def subscript_superscript_distortion(text: str, max_conversions: int = 2):\n",
    "    superscripts = {'0': '⁰', '1': '¹', '2': '²', '3': '³', '4': '⁴',\n",
    "                   '5': '⁵', '6': '⁶', '7': '⁷', '8': '⁸', '9': '⁹',\n",
    "                   'a': 'ᵃ', 'b': 'ᵇ', 'c': 'ᶜ', 'd': 'ᵈ', 'e': 'ᵉ'}\n",
    "    \n",
    "    subscripts = {'0': '₀', '1': '₁', '2': '₂', '3': '₃', '4': '₄',\n",
    "                 '5': '₅', '6': '₆', '7': '₇', '8': '₈', '9': '₉'}\n",
    "    \n",
    "    conversion_map = {**superscripts, **subscripts}\n",
    "    \n",
    "    text_list = list(text)\n",
    "    valid_indices = [i for i, ch in enumerate(text) if ch in conversion_map]\n",
    "    \n",
    "    if not valid_indices:\n",
    "        return text\n",
    "    \n",
    "    num_conversions = random.randint(1, min(max_conversions, len(valid_indices)))\n",
    "    conversion_indices = random.sample(valid_indices, k=num_conversions)\n",
    "    \n",
    "    for idx in conversion_indices:\n",
    "        text_list[idx] = conversion_map[text[idx]]\n",
    "    \n",
    "    return ''.join(text_list)\n",
    "\n",
    "\n",
    "def zalgo_distortion(text: str, max_intensity: int = 3, max_chars: int = 5):\n",
    "    \n",
    "    if(len(text)<=8):\n",
    "        return text\n",
    "    \"\"\"Adds stacking 'combining' diacritic marks to random characters.\"\"\"\n",
    "    # A selection of combining marks\n",
    "    DIACRITICS = [\n",
    "        # Above\n",
    "        '\\u0300', '\\u0301', '\\u0302', '\\u0303', '\\u0304', '\\u0305', '\\u0306', '\\u0307', \n",
    "        '\\u0308', '\\u030A', '\\u030B', '\\u030C', '\\u030D', '\\u030E', '\\u030F', '\\u0310', \n",
    "        '\\u0311',\n",
    "        # Middle (includes your strikethrough)\n",
    "        '\\u0334', '\\u0335', '\\u0336', '\\u0337', '\\u0338',\n",
    "        # Below\n",
    "        '\\u0316', '\\u0317', '\\u0318', '\\u0319', '\\u031A', '\\u031B', '\\u031C', '\\u031D',\n",
    "        '\\u031E', '\\u031F', '\\u0320', '\\u0321', '\\u0322', '\\u0323', '\\u0324', '\\u0325',\n",
    "        '\\u0326', '\\u0327', '\\u0328', '\\u0329', '\\u032A'\n",
    "    ]\n",
    "    \n",
    "    text_list = list(text)\n",
    "    \n",
    "    # Find non-space characters to distort\n",
    "    valid_indices = [i for i, char in enumerate(text) if not char.isspace()]\n",
    "    if not valid_indices:\n",
    "        return text\n",
    "\n",
    "    num_chars_to_distort = random.randint(1, min(max_chars, len(valid_indices)))\n",
    "    distort_indices = random.sample(valid_indices, k=num_chars_to_distort)\n",
    "    \n",
    "    for idx in sorted(distort_indices, reverse=True):\n",
    "        num_diacritics = random.randint(1, max_intensity)\n",
    "        for _ in range(num_diacritics):\n",
    "            text_list.insert(idx + 1, random.choice(DIACRITICS))\n",
    "    \n",
    "    return \"\".join(text_list)\n",
    "\n",
    "def render_faker_text_on_image(image, num_texts=5, font_path=None):\n",
    "    # img = Image.open(image_path)\n",
    "    # Initialize Faker\n",
    "    fake = Faker()\n",
    "    img=image.copy()\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    width, height = img.size\n",
    "\n",
    "    if font_path:\n",
    "        font = ImageFont.truetype(font_path, 12)\n",
    "    else:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for _ in range(num_texts):\n",
    "        text = fake.sentence()  # generate meaningful sentence dynamically\n",
    "        \n",
    "        x = random.randint(0, max(0, width - 100))\n",
    "        y = random.randint(0, max(0, height - 20))\n",
    "        color = tuple(random.randint(0,100) for _ in range(3))\n",
    "        draw.text((x, y), text, fill=color, font=font)\n",
    "\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def distort_text(example,distortion_list):\n",
    "    temp_example=example.copy()\n",
    "    text=temp_example['text']\n",
    "    \n",
    "    \n",
    "    \n",
    "    for ind in range(len(text)):\n",
    "        working_text=text[ind]\n",
    "        \n",
    "        if(working_text==''):\n",
    "            continue\n",
    "        else:\n",
    "            for distortion in distortion_list:\n",
    "                if(distortion==char_level_repetition_distortion):\n",
    "                    working_text=char_level_repetition_distortion(working_text)\n",
    "                elif(distortion==char_level_drop_distortion):\n",
    "                    working_text=char_level_drop_distortion(working_text)\n",
    "                elif(distortion==mirror_distortion):\n",
    "                    working_text=mirror_distortion(working_text)\n",
    "                elif(distortion==same_char_distortion):\n",
    "                    working_text=same_char_distortion(working_text)\n",
    "                elif(distortion==case_shuffle_distortion):\n",
    "                    working_text=case_shuffle_distortion(working_text)\n",
    "                elif(distortion==noise_injection_distortion):\n",
    "                    working_text=noise_injection_distortion(working_text)\n",
    "                elif(distortion==adjacent_char_swap_distortion):\n",
    "                    working_text=adjacent_char_swap_distortion(working_text)\n",
    "                elif(distortion==zalgo_distortion):\n",
    "                    working_text=zalgo_distortion(working_text)\n",
    "                elif(distortion==ocr_confusion_distortion):\n",
    "                    working_text=ocr_confusion_distortion(working_text)\n",
    "                elif(distortion==subscript_superscript_distortion):\n",
    "                    working_text=subscript_superscript_distortion(working_text)\n",
    "                    \n",
    "        \n",
    "        text[ind]=working_text\n",
    "        # print(\"Distorted text at index \",ind,\": \",working_text)\n",
    "    temp_example['text']=text\n",
    "    \n",
    "    # print(\"Second step pass\")\n",
    "    return temp_example\n",
    "\n",
    "def distort_image(img,distortion_type):\n",
    "    if(distortion_type=='faker_text'):\n",
    "        distorted_img=render_faker_text_on_image(img, num_texts=5)\n",
    "    return distorted_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afb6e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score(image, input_text, max_new_tokens=100):\n",
    "    \n",
    "    # prompt = \"\"\"Extract the text from the provided image. Remember dont print any extra text just return the text rendered on the image. Also try to ignore the lines or borders used for just styling\"\"\"\n",
    "    # messages = [\n",
    "    #     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    #     {\"role\": \"user\", \"content\": [\n",
    "    #         {\"type\": \"image\", \"image\": image},\n",
    "    #         {\"type\": \"text\", \"text\": prompt},\n",
    "    #     ]},\n",
    "    # ]\n",
    "    # text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    # inputs = processor(text=[text], images=[image], padding=True, return_tensors=\"pt\")\n",
    "    # inputs = inputs.to(model.device)\n",
    "    \n",
    "    # output_ids = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "    # generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(inputs.input_ids, output_ids)]\n",
    "    \n",
    "    # output_text = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    \n",
    "    # import Levenshtein\n",
    "    # val=Levenshtein.distance(output_text[0],input_text)\n",
    "    # return val\n",
    "    \n",
    "    return random.randint(0,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e3ed5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No better fallback found, 1 glyphs still missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIrst step pass\n",
      "Processing row 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No better fallback found, 1 glyphs still missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distortion time: 7.03 seconds\n",
      "Distortion time: 12.85 seconds\n",
      "Distortion time: 3.74 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No better fallback found, 1 glyphs still missing\n",
      "No better fallback found, 1 glyphs still missing\n",
      "No better fallback found, 1 glyphs still missing\n",
      "No better fallback found, 1 glyphs still missing\n",
      "No better fallback found, 1 glyphs still missing\n",
      "No better fallback found, 1 glyphs still missing\n",
      "No better fallback found, 1 glyphs still missing\n",
      "No better fallback found, 1 glyphs still missing\n",
      "No better fallback found, 1 glyphs still missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distortion time: 5.83 seconds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty range in randrange(1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 110\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distorted\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_sample):\n\u001b[1;32m--> 110\u001b[0m     distorted\u001b[38;5;241m=\u001b[39m\u001b[43mgenerate_distorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m distorted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 94\u001b[0m, in \u001b[0;36mgenerate_distorted\u001b[1;34m(example, ind)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m available_distortions_image_only:\n\u001b[0;32m     92\u001b[0m         flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 94\u001b[0m distorted \u001b[38;5;241m=\u001b[39m \u001b[43mdistort_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfuncs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# print(distorted['text'])\u001b[39;00m\n\u001b[0;32m     96\u001b[0m distorted \u001b[38;5;241m=\u001b[39m renderer\u001b[38;5;241m.\u001b[39mrender(distorted)\n",
      "Cell \u001b[1;32mIn[18], line 287\u001b[0m, in \u001b[0;36mdistort_text\u001b[1;34m(example, distortion_list)\u001b[0m\n\u001b[0;32m    285\u001b[0m     working_text\u001b[38;5;241m=\u001b[39mchar_level_repetition_distortion(working_text)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(distortion\u001b[38;5;241m==\u001b[39mchar_level_drop_distortion):\n\u001b[1;32m--> 287\u001b[0m     working_text\u001b[38;5;241m=\u001b[39m\u001b[43mchar_level_drop_distortion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworking_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(distortion\u001b[38;5;241m==\u001b[39mmirror_distortion):\n\u001b[0;32m    289\u001b[0m     working_text\u001b[38;5;241m=\u001b[39mmirror_distortion(working_text)\n",
      "Cell \u001b[1;32mIn[18], line 48\u001b[0m, in \u001b[0;36mchar_level_drop_distortion\u001b[1;34m(text, max_drops)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchar_level_drop_distortion\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, max_drops: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 48\u001b[0m     num_drops \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_drops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     drop_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(text)), k\u001b[38;5;241m=\u001b[39mnum_drops))\n\u001b[0;32m     51\u001b[0m     distorted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(ch \u001b[38;5;28;01mfor\u001b[39;00m i, ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(text) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m drop_indices)\n",
      "File \u001b[1;32mc:\\Users\\pulki\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\random.py:336\u001b[0m, in \u001b[0;36mRandom.randint\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandint\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, b):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return random integer in range [a, b], including both end points.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pulki\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\random.py:319\u001b[0m, in \u001b[0;36mRandom.randrange\u001b[1;34m(self, start, stop, step)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m istart \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(width)\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty range in randrange(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# Non-unit step argument supplied.\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m istep \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: empty range in randrange(1, 1)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # # Pulkit- Just change the start and end values\n",
    "    start=0\n",
    "    end=10\n",
    "    type_of_process=1 \n",
    "    min_val=3\n",
    "    max_val=11\n",
    "    total_sample=150\n",
    "    batch_size=16\n",
    "\n",
    "    output_dir = \"dataset\"\n",
    "    final_csv_path=os.path.join(output_dir,f\"final_dataset_{start}_{end}\")\n",
    "    final_json_path=os.path.join(output_dir,f\"scores_data_{start}_{end}\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "        os.mkdir(os.path.join(output_dir, \"win\"))\n",
    "        for n in range(1, batch_size+1):  \n",
    "            os.mkdir(os.path.join(output_dir, f\"lose{n}\"))\n",
    "\n",
    "\n",
    "    # Load the dataset from Hugging Face\n",
    "    dataset = datasets.load_from_disk(\"my_dataset\")\n",
    "    renderer = CrelloV5Renderer(dataset.features, fonts_path)\n",
    "\n",
    "    available_distortions_text_only = [\n",
    "        char_level_drop_distortion,\n",
    "        char_level_repetition_distortion,\n",
    "        adjacent_char_swap_distortion,\n",
    "        case_shuffle_distortion,\n",
    "        noise_injection_distortion,\n",
    "        ocr_confusion_distortion,\n",
    "        subscript_superscript_distortion,\n",
    "        zalgo_distortion,\n",
    "        mirror_distortion,\n",
    "        same_char_distortion,\n",
    "    ]\n",
    "    \n",
    "    available_distortions_image_only = [\n",
    "        render_faker_text_on_image,\n",
    "    ]\n",
    "    \n",
    "    available_distortion=available_distortions_text_only + available_distortions_image_only\n",
    "\n",
    "    lose_cols = [f\"lose_image{i}\" for i in range(1, batch_size+1)]\n",
    "    final_dataset = pd.DataFrame(columns=[\"prompt\", \"win_image\"] + lose_cols)\n",
    "\n",
    "    print(\"FIrst step pass\")\n",
    "    json_dict_for_scores=[]\n",
    "    \n",
    "    for i in range(start,end):\n",
    "\n",
    "        temp_dict={}\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing row {i}\")\n",
    "            \n",
    "        example = dataset[i]\n",
    "        # print(example)\n",
    "        # try:\n",
    "            \n",
    "            \n",
    "        win_image = renderer.render(example)\n",
    "        win_image = Image.open(BytesIO(win_image))\n",
    "        \n",
    "         # Save win image\n",
    "        win_path = os.path.join(output_dir, \"win\", f\"{i}.png\")\n",
    "        # cv2.imwrite(win_path, np.array(win_image))\n",
    "        win_image.save(win_path, format=\"PNG\", optimize=True)\n",
    "\n",
    "        if win_image is None:\n",
    "            continue\n",
    "\n",
    "        distorted_images = []\n",
    "\n",
    "        # Generate 100 distorted images\n",
    "        import time\n",
    "        start=time.time()\n",
    "        \n",
    "\n",
    "        def generate_distorted(example, ind):\n",
    "            \n",
    "            num_ops = random.randint(3, len(available_distortion))\n",
    "\n",
    "            funcs = random.choices(available_distortion, k=1)\n",
    "            flag=0\n",
    "            \n",
    "            for i in funcs:\n",
    "                if i in available_distortions_image_only:\n",
    "                    flag=1\n",
    "                    \n",
    "            distorted = distort_text(example,funcs)\n",
    "            # print(distorted['text'])\n",
    "            distorted = renderer.render(distorted)\n",
    "            distorted=Image.open(BytesIO(distorted))\n",
    "            # distorted.show()\n",
    "            # print(distorted)\n",
    "            # if flag==1:\n",
    "                \n",
    "            #     distorted=distort_image(distorted,'faker_text')\n",
    "                \n",
    "            if distorted is None:\n",
    "                return None\n",
    "            return distorted\n",
    "\n",
    "        \n",
    "        for ind in range(total_sample):\n",
    "            distorted=generate_distorted(example, ind)\n",
    "            if distorted is None:\n",
    "                continue\n",
    "            score_val=score(distorted, example['text'])\n",
    "            distorted_images.append((distorted, score_val))\n",
    "        \n",
    "        if i % 200 == 0:  # Note: Use ==, not just `if i % 200`\n",
    "            save_folder_path=os.path.join(output_dir, f\"ckpt_{i}\")\n",
    "            os.makedirs(save_folder_path, exist_ok=True)\n",
    "            for idx, (img, _) in enumerate(distorted_images):\n",
    "                save_path=os.path.join(save_folder_path,f'{idx}.png')\n",
    "                # cv2.imwrite(save_path, np.array(img))\n",
    "                img.save(save_path)\n",
    "\n",
    "\n",
    "        print(f\"Distortion time: {time.time() - start:.2f} seconds\")\n",
    "        def max_variation_dp(data, k):\n",
    "            from functools import lru_cache\n",
    "\n",
    "            data = sorted(data, key=lambda x: x[1])\n",
    "            values = [val for val in data]\n",
    "            scores = [val[1] for val in data]\n",
    "            N = len(data)\n",
    "\n",
    "            # Use indices instead of actual score values to make caching effective\n",
    "            @lru_cache(maxsize=None)\n",
    "            def dp(pos, rem, last_idx):\n",
    "                if rem == 0:\n",
    "                    return 0, []\n",
    "                if pos == N:\n",
    "                    return float(\"-inf\"), []\n",
    "\n",
    "                # Option 1: Take current element\n",
    "                take_score = abs(scores[pos] - scores[last_idx]) if last_idx != -1 else 0\n",
    "                take_sum, take_list = dp(pos + 1, rem - 1, pos)\n",
    "                take_sum += take_score\n",
    "\n",
    "                # Option 2: Skip current element\n",
    "                skip_sum, skip_list = dp(pos + 1, rem, last_idx)\n",
    "\n",
    "                if take_sum > skip_sum:\n",
    "                    return take_sum, [values[pos]] + take_list\n",
    "                else:\n",
    "                    return skip_sum, skip_list\n",
    "\n",
    "            _, best_subset = dp(0, k, -1)\n",
    "            return best_subset\n",
    "\n",
    "\n",
    "        distorted_images = sorted(distorted_images, key=lambda x: x[1])\n",
    "        distorted_images1= distorted_images[:len(distorted_images)//3]\n",
    "        distorted_images2= distorted_images[len(distorted_images)//3:len(distorted_images)//2]\n",
    "        distorted_images3= distorted_images[len(distorted_images)//2:]\n",
    "        sample_from_each_bucket=batch_size//3\n",
    "        best_subset = max_variation_dp(distorted_images1, k=sample_from_each_bucket)\n",
    "        best_subset += max_variation_dp(distorted_images2, k=sample_from_each_bucket)\n",
    "        best_subset+=max_variation_dp(distorted_images3, k=batch_size-2*sample_from_each_bucket)\n",
    "\n",
    "        best_subset=sorted(best_subset, key=lambda x: x[1])\n",
    "        if len(best_subset) < batch_size:\n",
    "            continue\n",
    "\n",
    "       \n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        lose_paths = []\n",
    "        for j, (img, score_val) in enumerate(best_subset):\n",
    "            path = os.path.join(output_dir, f\"lose{j+1}\", f\"{i}.png\")\n",
    "            img.save(path)\n",
    "            lose_paths.append(path)\n",
    "            temp_dict[j+1]=score_val\n",
    "\n",
    "        win_image_score= score(win_image, example['text'])\n",
    "        temp_dict['win_image_score']=win_image_score\n",
    "\n",
    "        #Pulkit- Comment this line to avoid visualization\n",
    "        # visualize_generated_dataset(best_subset, win_image, prompt,win_image_score)\n",
    "\n",
    "        # Append to final dataset\n",
    "        data_row = {\"prompt\": example['text'], \"win_image\": win_path}\n",
    "        for k in range(batch_size):\n",
    "            data_row[f\"lose_image{k+1}\"] = lose_paths[k]\n",
    "\n",
    "        final_dataset = pd.concat([final_dataset, pd.DataFrame([data_row])], ignore_index=True)\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error on row {i}: {e}\")\n",
    "        #     continue\n",
    "\n",
    "        json_dict_for_scores.append({i: temp_dict})\n",
    "        # if i%100==0:\n",
    "        with open(final_json_path,'w') as f:\n",
    "            json.dump(json_dict_for_scores, f, indent=4)\n",
    "    # Save full dataset\n",
    "    final_dataset.to_csv(final_csv_path, index=False)\n",
    "\n",
    "   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461e244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
